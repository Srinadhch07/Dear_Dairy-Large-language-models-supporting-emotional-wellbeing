Features / Enhancements:
----------------------------
Emotion Detection::
---------------------
Using NLP models (Gemma:2B, Gemini API).

Option to use HuggingFace datasets (e.g., dair-ai/emotion, go_emotions).

AI Replies:

Empathetic, supportive responses tailored to mood.

Avoid "fixed replies" â†’ dynamic generation.

Use Gemini / Gemma to improve naturalness.

Mood Insights & Trends:
-----------------------
Dashboard to show mood patterns over time.

Graphs/visualizations of emotions (weekly/monthly/yearly).

Personalized Suggestions:
---------------------------
Motivational quotes.

Relaxation techniques.

Journaling prompts.

AI-generated coping strategies.

Interactive UI Ideas:
--------------------------------
Beautiful home page with attractive CSS (cards, Bootstrap theme, gradients).

Past entries page styled with bright CSS.

Entries displayed as cards with date, text, emotion, and AI reply.

Storage:
--------
Save text + emotion + AI reply into SQLite (or MongoDB if scaling).

ðŸ”¹ Technical Stack We Discussed
---------------------------------
Frontend: Django templates + Bootstrap + custom CSS.

Backend: Django + SQLite (later MongoDB).

AI Models: Gemma:2B (local) + Gemini API (for replies).

Visualization: Dashboards for mood patterns.

ðŸ”¹ Future Expansion Ideas
--------------------------
SaaS version (multi-user with login).

Mobile app (React Native / Flutter frontend).

Community feature (share diary entries anonymously, optional).

Subscription plan for premium features (deep insights, longer storage, AI-powered advice).





# detected_emotion, score = predict_emotion(text)
        # emotion = classifier(text)
        # # top_emotion = emotion[0][0]
        # print(f'emotion-english-distilroberta-base',detected_emotion)
        # print(f'oeddav/distilbert-base-uncased-go-emotions-student: {top_emotion['label']}')

        # Option 1: automated model shift (recommended)
        # try:
        #     ai_reply = generate_gemma_replay(text)
        # except:
        #     ai_reply = generate_tinyllama_reply(text, detected_emotion)

        # Option 2: Any one model runs based on requirements
         # LLM - Machine dependent
        # ai_reply = generate_tinyllama_reply(text, detected_emotion)
        # ai_reply = generate_gemmaLLM_reply(text)